{
  "model": {
    "model_name": "Qwen/Qwen3-1.7B",
    "num_layers": 28,
    "parameters": {
      "total_parameters_bytes": 8126959616,
      "parameters_per_layer_bytes": [
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282,
        88115536.10503282
      ]
    }
  },
  "execution_time": {
    "total_time_ms": 5842.106019914012,
    "forward_backward_time_ms": 6409.096147961377,
    "batch_generator_time_ms": 3.845581639134193,
    "layernorm_grads_all_reduce_time_ms": 0.0087527352297593,
    "embedding_grads_all_reduce_time_ms": 0.0175054704595186,
    "optimizer_time_ms": 848.1648557409543,
    "layer_compute_total_ms": [
      199.06953173838312,
      200.27034628766444,
      194.4227273465405,
      194.11609124843667,
      189.89212177459484,
      182.9767843549949,
      184.2983297509991,
      179.30865634861453,
      176.19034102445374,
      179.0336175022863,
      173.66764573553573,
      176.07410229983,
      176.2333560209717,
      174.04651346502325,
      174.34112878319658,
      174.00026105265837,
      174.00426914685158,
      176.95508764076496,
      174.63494102033445,
      176.87417713250696,
      174.69631935570683,
      174.55069115003306,
      174.91478994014903,
      170.260575935968,
      165.67778983892143,
      165.05389473822856,
      164.96772637144466,
      169.5375073231406
    ]
  },
  "execution_memory": {
    "total_memory": 88397.4453125,
    "layer_memory_total_mb": [
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986,
      1344.5363785557986
    ]
  }
}